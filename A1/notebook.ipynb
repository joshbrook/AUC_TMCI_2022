{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    "> Remember to add an explanation of what you do using markdown, and to comment your code. Please *be brief*.\n",
    ">\n",
    "> If you re-use a substantial portion of code you find online, e.g on Stackoverflow, you need to add a link to it and make the borrowing explicit. The same applies of you take it and modify it, even substantially. There is nothing bad in doing that, providing you are acknowledging it and make it clear you know what you're doing.\n",
    ">\n",
    "> Make sure your notebooks have been run when you sumit, as I won't run them myself. Submit both the `.ipynb` file along with an `.html` export of the same. Submit all necessary auxilliary files as well. Please compress your submission into a `.zip` archive. Only `.zip` files can be submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading policy\n",
    "> As follows:\n",
    ">\n",
    "> * 70 points for correctly completing the assignment.\n",
    ">\n",
    "> * 20 points for appropriately writing and organizing your code in terms of structure, readibility (also by humans), comments and minimal documentation. It is important to be concise but also to explain what you did and why, when not obvious.\n",
    "> \n",
    "> * 10 points for doing something extra, e.g., if you go beyond expectations (overall or on something specific). Some ideas for extras might be mentioned in the exercises, or you can come up with your own. You don't need to do them all to get the bonus. The sum of points is 90, doing (some of) the extras can bring you to 100, so the extras are not necessary to get an A.\n",
    "> \n",
    "\n",
    "**The AUC code of conduct applies to this assignment: please only submit your own work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm up (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 1 (2 points)\n",
    "\n",
    "Explain why `list1` and `list2` behave differently when they are passed to the `append_to_nested_list()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Python'], [], []]\n",
      "[['Python'], ['Python'], ['Python']]\n"
     ]
    }
   ],
   "source": [
    "def append_to_nested_list(a_list):\n",
    "    a_list[0].append(\"Python\")\n",
    "    return a_list\n",
    "    \n",
    "list1 = [[], [], []]\n",
    "list2 = [[]] * 3\n",
    "\n",
    "print(append_to_nested_list(list1))\n",
    "print(append_to_nested_list(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# your code or explanation here\n",
    "x = ([[]] * 3)[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (3 points)\n",
    "\n",
    "Write a function that counts the frequency of all words that start and end with the same character (e.g. comic) in a text file and test it on `data/melville-md.txt`. \n",
    "\n",
    "Ensure that the words are treated case-insensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency of all words that start and end with the same character in this file is 14305\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "file = open(\"data/melville-md.txt\", \"r\", encoding='utf-8')\n",
    "raw = file.read()\n",
    "file.close()\n",
    "\n",
    "# searching for the positions of the real start and end of the text, in order to strip the excess\n",
    "raw.find(\"Call me Ishmael\")\n",
    "raw.find(\"This file should be named 2701-h.htm or 2701-h.zip\")\n",
    "raw = raw[28029:1219900].lower()\n",
    "\n",
    "# removing punctuation and splitting on words\n",
    "t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "words = raw.translate(t).split()\n",
    "\n",
    "freq = 0\n",
    "for word in words:\n",
    "    if word[0] == word[-1]:\n",
    "        freq +=1\n",
    "    \n",
    "# final result\n",
    "print(\"The frequency of all words that start and end with the same character in this file is\", freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text from Project Gutenberg contains a header and a footer with the name of the text, references, and the author, etc. I had to manually search for the positions of the real start and end of the text, in order to strip the excess\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (3 points)\n",
    "\n",
    "Rewrite the following code such that:\n",
    "\n",
    "- the sequence of fruit names are randomly presented (without replacement). Use a function in the [random](https://docs.python.org/3.7/library/random.html) module for this.\n",
    "\n",
    "\n",
    "- the article \"an\" is used when a fruit name begins with a vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a apple\n",
      "We have a apricot\n",
      "We have a avocado\n",
      "We have a banana\n",
      "We have a bilberry\n",
      "We have a blackberry\n",
      "We have a blackcurrant\n",
      "We have a blueberry\n",
      "We have a boysenberry\n",
      "We have a currant\n",
      "We have a cherry\n",
      "We have a cherimoya\n",
      "We have a cloudberry\n",
      "We have a coconut\n",
      "We have a cranberry\n",
      "We have a cucumber\n",
      "We have a damson\n",
      "We have a date\n",
      "We have a dragonfruit\n",
      "We have a durian\n",
      "We have a elderberry\n",
      "We have a feijoa\n",
      "We have a fig\n",
      "We have a gooseberry\n",
      "We have a grape\n",
      "We have a raisin\n",
      "We have a grapefruit\n",
      "We have a guava\n",
      "We have a honeyberry\n",
      "We have a huckleberry\n",
      "We have a jabuticaba\n",
      "We have a jackfruit\n",
      "We have a jambul\n",
      "We have a jujube\n",
      "We have a kiwano\n",
      "We have a kiwifruit\n",
      "We have a kumquat\n",
      "We have a lemon\n",
      "We have a lime\n",
      "We have a loquat\n",
      "We have a longan\n",
      "We have a lychee\n",
      "We have a mango\n",
      "We have a mangosteen\n",
      "We have a marionberry\n",
      "We have a melon\n",
      "We have a cantaloupe\n",
      "We have a honeydew\n",
      "We have a watermelon\n",
      "We have a mulberry\n",
      "We have a nectarine\n",
      "We have a nance\n",
      "We have a orange\n",
      "We have a clementine\n",
      "We have a mandarine\n",
      "We have a tangerine\n",
      "We have a papaya\n",
      "We have a passionfruit\n",
      "We have a peach\n",
      "We have a pear\n",
      "We have a persimmon\n",
      "We have a physalis\n",
      "We have a plantain\n",
      "We have a plum\n",
      "We have a prune\n",
      "We have a pineapple\n",
      "We have a plumcot\n",
      "We have a pomegranate\n",
      "We have a pomelo\n",
      "We have a quince\n",
      "We have a raspberry\n",
      "We have a salmonberry\n",
      "We have a rambutan\n",
      "We have a redcurrant\n",
      "We have a salak\n",
      "We have a satsuma\n",
      "We have a soursop\n",
      "We have a strawberry\n",
      "We have a tamarillo\n",
      "We have a tamarind\n",
      "We have a yuzu\n"
     ]
    }
   ],
   "source": [
    "available_fruit = ['apple', 'apricot', 'avocado', 'banana', 'bilberry', 'blackberry', 'blackcurrant', 'blueberry', 'boysenberry', 'currant', 'cherry', 'cherimoya', 'cloudberry', 'coconut', 'cranberry', 'cucumber', 'damson', 'date', 'dragonfruit', 'durian', 'elderberry', 'feijoa', 'fig', 'gooseberry', 'grape', 'raisin', 'grapefruit', 'guava', 'honeyberry', 'huckleberry', 'jabuticaba', 'jackfruit', 'jambul', 'jujube', 'kiwano', 'kiwifruit', 'kumquat', 'lemon', 'lime', 'loquat', 'longan', 'lychee', 'mango', 'mangosteen', 'marionberry', 'melon', 'cantaloupe', 'honeydew', 'watermelon', 'mulberry', 'nectarine', 'nance', 'orange', 'clementine', 'mandarine', 'tangerine', 'papaya', 'passionfruit', 'peach', 'pear', 'persimmon', 'physalis', 'plantain', 'plum', 'prune', 'pineapple', 'plumcot', 'pomegranate', 'pomelo', 'quince', 'raspberry', 'salmonberry', 'rambutan', 'redcurrant', 'salak', 'satsuma', 'soursop', 'strawberry', 'tamarillo', 'tamarind', 'yuzu']\n",
    "\n",
    "for fruit in available_fruit:\n",
    "    print(\"We have a \" + fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a passionfruit\n",
      "We have a physalis\n",
      "We have a kiwano\n",
      "We have a jabuticaba\n",
      "We have a clementine\n",
      "We have a watermelon\n",
      "We have a nance\n",
      "We have a cranberry\n",
      "We have a peach\n",
      "We have a marionberry\n",
      "We have a mulberry\n",
      "We have a plumcot\n",
      "We have a jujube\n",
      "We have a durian\n",
      "We have a lime\n",
      "We have an avocado\n",
      "We have an elderberry\n",
      "We have a salak\n",
      "We have a rambutan\n",
      "We have a nectarine\n",
      "We have a papaya\n",
      "We have a persimmon\n",
      "We have a loquat\n",
      "We have a pineapple\n",
      "We have a grapefruit\n",
      "We have a plum\n",
      "We have a blueberry\n",
      "We have a raspberry\n",
      "We have a pomelo\n",
      "We have a plantain\n",
      "We have an apple\n",
      "We have a jackfruit\n",
      "We have a fig\n",
      "We have a dragonfruit\n",
      "We have a date\n",
      "We have a cherry\n",
      "We have a mango\n",
      "We have a coconut\n",
      "We have a cucumber\n",
      "We have a huckleberry\n",
      "We have a melon\n",
      "We have a tamarind\n",
      "We have a prune\n",
      "We have an apricot\n",
      "We have a raisin\n",
      "We have a lychee\n",
      "We have an orange\n",
      "We have a banana\n",
      "We have a soursop\n",
      "We have a cantaloupe\n",
      "We have a mangosteen\n",
      "We have a quince\n",
      "We have a lemon\n",
      "We have a redcurrant\n",
      "We have a currant\n",
      "We have a yuzu\n",
      "We have a blackberry\n",
      "We have a honeydew\n",
      "We have a satsuma\n",
      "We have a cloudberry\n",
      "We have a kumquat\n",
      "We have a jambul\n",
      "We have a pomegranate\n",
      "We have a honeyberry\n",
      "We have a feijoa\n",
      "We have a boysenberry\n",
      "We have a grape\n",
      "We have a mandarine\n",
      "We have a bilberry\n",
      "We have a blackcurrant\n",
      "We have a damson\n",
      "We have a tamarillo\n",
      "We have a cherimoya\n",
      "We have a gooseberry\n",
      "We have a tangerine\n",
      "We have a guava\n",
      "We have a salmonberry\n",
      "We have a kiwifruit\n",
      "We have a longan\n",
      "We have a pear\n",
      "We have a strawberry\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import random\n",
    "\n",
    "available_fruit = ['apple', 'apricot', 'avocado', 'banana', 'bilberry', 'blackberry', 'blackcurrant', 'blueberry', 'boysenberry', 'currant', 'cherry', 'cherimoya', 'cloudberry', 'coconut', 'cranberry', 'cucumber', 'damson', 'date', 'dragonfruit', 'durian', 'elderberry', 'feijoa', 'fig', 'gooseberry', 'grape', 'raisin', 'grapefruit', 'guava', 'honeyberry', 'huckleberry', 'jabuticaba', 'jackfruit', 'jambul', 'jujube', 'kiwano', 'kiwifruit', 'kumquat', 'lemon', 'lime', 'loquat', 'longan', 'lychee', 'mango', 'mangosteen', 'marionberry', 'melon', 'cantaloupe', 'honeydew', 'watermelon', 'mulberry', 'nectarine', 'nance', 'orange', 'clementine', 'mandarine', 'tangerine', 'papaya', 'passionfruit', 'peach', 'pear', 'persimmon', 'physalis', 'plantain', 'plum', 'prune', 'pineapple', 'plumcot', 'pomegranate', 'pomelo', 'quince', 'raspberry', 'salmonberry', 'rambutan', 'redcurrant', 'salak', 'satsuma', 'soursop', 'strawberry', 'tamarillo', 'tamarind', 'yuzu']\n",
    "\n",
    "random.shuffle(available_fruit)\n",
    "\n",
    "for fruit in available_fruit:\n",
    "    if fruit[0] in \"aeiou\":\n",
    "        print(\"We have an \" + fruit)\n",
    "    else:\n",
    "        print(\"We have a \" + fruit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (7 points)\n",
    "\n",
    "The following code has been written to extract all word-initial consonant clusters in a text (e.g. \"br\" in \"bread). Each sequence is obtained by matching any sequence of letters that does not include 'aeiou' and that occurs after a whitespace or the start of the line and that consists of 2 or more such characters.\n",
    "\n",
    "It works by reading an input file line by line, and finding all matches of a regular expression in this line (case insensitive).\n",
    "\n",
    "Unfortunately, the method only counts, and we do not find out which word-initial consonants are present in the text. Can you find a way to save all matching consonant clusters to the dictionary named \"consonantclusters\" with their frequency as the value, and then print this dictionary? Note that there can be multiple results per line. Try to avoid capturing the space(s) before the consonant cluster also.\n",
    "\n",
    "**Possible extra:** Print the consonant clusters sorted by frequency and in a nice looking way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51523\n"
     ]
    }
   ],
   "source": [
    "consonantclusters = {}\n",
    "consonantclustercount = 0\n",
    "with codecs.open(\"data/melville-md.txt\", \"r\", encoding=\"utf8\") as infile:\n",
    "    consonantclusterregex = re.compile(r'(^|\\s)(?:(?![aeiouy])[a-z]){2,}')\n",
    "    for line in infile:\n",
    "        result = consonantclusterregex.findall(line.lower())\n",
    "        if result:\n",
    "            consonantclustercount += len(result)\n",
    "print(consonantclustercount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 5 (10 points)\n",
    "\n",
    "Please use the frequencies in `late_arrival_causes` to create a duplicate of the plot below, as close as possible. This is called a Pareto chart.\n",
    "\n",
    "Note: the line plot above the bars shows the cumulative frequency.\n",
    "\n",
    "**Possible extra:** suggest, motivate and implement an alternative visualization for the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pareto chart](images/pareto-chart.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_arrival_causes = {\"Child Care\" : 44, \"Emergency\" : 7, \"Overslept\" : 11, \"Traffic\" : 56, \"Transp.\" : 27, \"Weather\" : 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipelines (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (25 points)\n",
    "\n",
    "- Download a 19th-century edition (or earlier, but not later!) of a book you like from the [Internet Archive](https://archive.org) in `.txt` format. For example, [Frankenstein](https://archive.org/details/ghostseer01schiuoft/page/n6). Add the link to the edition you used to your answer, as well as the `.txt` file to your submission.\n",
    "\n",
    "- Write code that:\n",
    "\n",
    "    1. Reads the text in memory.\n",
    "    \n",
    "    1. Pre-processes the text with a tokenizer from [NLTK](https://www.nltk.org/api/nltk.tokenize.html) (remember to motivate your choice).\n",
    "    \n",
    "    1. Filter out words that consist of strictly less than 4 alphabetic characters.\n",
    "\n",
    "    1. Counts the frequencies of all the words in the corpus (words should be counted case-insensitive).\n",
    "\n",
    "    1. Writes each word-frequency pair to a csv file (from most frequent to rarest).\n",
    "\n",
    "*Briefly* comment on your results, especially looking at very frequent and very unfrequent words. What is problematic about these old editions? Can you find some limitations of the tokenizer in use, and think about how you would improve on it?\n",
    "\n",
    "**Possible extra:** plot the relative frequency of the top N words (e.g., use the Pareto chart you did above, or another suitable plot) and discuss whether the distribution might follow the [Zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law).\n",
    "\n",
    "**Possible extra:** add lemmatization or stemming and part-of-speech tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (15 points)\n",
    "\n",
    "Do some self-learning: implement the same pipeline of question 6 using [spaCy pipelines](https://spacy.io/usage/processing-pipelines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text similarity (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 (25 points)\n",
    "\n",
    "The **Levenshtein Distance** (see [Wikipedia](https://en.wikipedia.org/wiki/Levenshtein_distance) and J&M, Ch. 2.5) calculates the distance between two strings as the number of deletions, insertions, or substitutions required to transform one into the other. This is also called edit distance. **Write a reasonably efficient function to calculate this metric**.\n",
    "\n",
    "Examples: \n",
    "\n",
    "* `levenshtein(\" Hello \", \"hello\")` returns 3 (case sensitive)\n",
    "* `levenshtein(\"aeiou\", \"aeiouuu\")` returns 2\n",
    "\n",
    "Remarks:\n",
    "\n",
    "- **Important:** a (naive) recursive implementation is going to be very slow, so one way to ensure the function is efficient is by making it *iterative*. That said, there are also ways to speed up a recursive implementation. In the end, how you implement it is up to you, as long as it works.\n",
    "\n",
    "\n",
    "- The Wikipedia article discusses the difference between a (slow) recursive strategy and a (fast) iterative one.\n",
    "\n",
    "\n",
    "- Test your function with `%timeit` on two words with a high distance, e.g. \"levenshteindistance\" vs. \"ecnatsidniethsnevel\". If your function takes seconds to compute the distance, it's too slow. A moderately fast iterative function finishes in 100-200 ns on my computer.\n",
    "\n",
    "\n",
    "- This exercise only consists of writing a single function, so the threshold for **code originality** is higher here than in other exercises. The code for this exercise must be your own. If I find the code submitted to this exercise somewhere online (even with small changes like new variable names) it will be graded 0 points. Submitting a slow function that you wrote yourself is better than submitting a fast, but copied function.\n",
    "\n",
    "\n",
    "- Carefully comment your code in order to explain what your function is doing. **In this case, uncommented code will not be graded at all**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
