{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    "> Remember to add an explanation of what you do using markdown, and to comment your code. Please *be brief*.\n",
    ">\n",
    "> If you re-use a substantial portion of code you find online, e.g on Stackoverflow, you need to add a link to it and make the borrowing explicit. The same applies of you take it and modify it, even substantially. There is nothing bad in doing that, providing you are acknowledging it and make it clear you know what you're doing.\n",
    ">\n",
    "> Make sure your notebooks have been run when you sumit, as I won't run them myself. Submit both the `.ipynb` file along with an `.html` export of the same. Submit all necessary auxilliary files as well. Please compress your submission into a `.zip` archive. Only `.zip` files can be submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading policy\n",
    "> As follows:\n",
    ">\n",
    "> * 70 points for correctly completing the assignment.\n",
    ">\n",
    "> * 20 points for appropriately writing and organizing your code in terms of structure, readibility (also by humans), comments and minimal documentation. It is important to be concise but also to explain what you did and why, when not obvious.\n",
    "> \n",
    "> * 10 points for doing something extra, e.g., if you go beyond expectations (overall or on something specific). Some ideas for extras might be mentioned in the exercises, or you can come up with your own. You don't need to do them all to get the bonus. The sum of points is 90, doing (some of) the extras can bring you to 100, so the extras are not necessary to get an A.\n",
    "> \n",
    "\n",
    "**The AUC code of conduct applies to this assignment: please only submit your own work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this assignment, you will build and compare vector models for measuring **semantic similarity**.\n",
    "\n",
    "First, you are going to use different count-based methods to create these models. Secondly you are going to created dense, lower-dimensionality models from them. Thirdly, you are going to use prediction-based models as well.\n",
    "\n",
    "Eventually, you are asked to assess the performance of these models against a human gold standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus preparation (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "Create one distributional space by **counting and filtering** the surface co-occurrences in a symmetric ±5 word collocations span from the following corpus:\n",
    "\n",
    "* A lemmatized version of the Reuters corpus (the choice of the lemmatizer is up to you). For this step, you might need a PoS-tagger: you are welcome to choose one yourself. In case you can't do PoS tagging on your own, you can use the following command to load the provided corpus in `data/reuters.pos` (uploaded as a `.zip` file, so first unzip it):\n",
    "\n",
    "```python\n",
    "with open(\"data/reuters.pos\", \"rb\") as corpus_file:\n",
    "    reuter_PoSTagged = pickle.load(corpus_file)\n",
    "```\n",
    "\n",
    "Remember to make motivated choices for the different strategies in building word vectors as described in class. Be explicit about:\n",
    "\n",
    "1. what lemmas you want to describe (i.e., what will be your target vectors?);\n",
    "2. how you want to describe them (i.e., what will be your contexts?);\n",
    "3. what filtering strategy you are going to choose (i.e., what do you exclude?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('much', 'r'),\n",
       " ('more', 'r'),\n",
       " ('serious', 'a'),\n",
       " ('for', None),\n",
       " ('hong', 'n'),\n",
       " ('kong', 'n'),\n",
       " ('be', 'v'),\n",
       " ('the', None),\n",
       " ('disadvantage', 'n'),\n",
       " ('of', None),\n",
       " ('action', 'n'),\n",
       " ('restrain', 'v'),\n",
       " ('trade,', 'n'),\n",
       " ('he', None),\n",
       " ('say', 'v'),\n",
       " ('the', None),\n",
       " ('u.s', 'n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import reuters\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "sentences = reuters.raw().lower().split(\". \")\n",
    "\n",
    "regextk = RegexpTokenizer('\\s+', gaps = True)\n",
    "\n",
    "tok_sents = [regextk.tokenize(s) for s in sentences]\n",
    "\n",
    "tagged = [nltk.pos_tag(sent) for sent in tok_sents]\n",
    "\n",
    "\n",
    "def wn_pos(tag):\n",
    "    \"converts treebank tags into wordbank tags for lemmatization\"\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    \n",
    "    if tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    \n",
    "    if tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    \n",
    "    if tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    \n",
    "    return None\n",
    "\n",
    "lem_sents = []\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "for sent in tagged:\n",
    "    lemmas = []\n",
    "    for word, tag in sent:\n",
    "        try:\n",
    "            wn_tag = wn_pos(tag)\n",
    "            if word[0] in string.punctuation:\n",
    "                word = word[1:]\n",
    "            if word[-1] in string.punctuation:\n",
    "                word = word[:-1]\n",
    "            if wn_tag is None:\n",
    "                # append lemmatized word to list\n",
    "                lemmas.append((lem.lemmatize(word), wn_tag))\n",
    "            else:\n",
    "                # use PoS tag for more accurate lemmatization\n",
    "                lemmas.append((lem.lemmatize(word, wn_tag), wn_tag))\n",
    "        except IndexError:        \n",
    "            pass\n",
    "        \n",
    "    lem_sents.append(lemmas)\n",
    "\n",
    "lemmas = [lem for sentence in lem_sents for lem in sentence]\n",
    "\n",
    "# arbitrary lemmatized sentence as an example\n",
    "lem_sents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is now a lemmatized version of the reuters corpus, which can be split by sentence or treated as a huge list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact alternate implementation with spacy\n",
    "# DO NOT RUN - USES TOO MUCH MEMORY\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "nlp.max_length = 10_000_000\n",
    "\n",
    "doc = nlp(reuters.raw().lower())\n",
    "\n",
    "reuters_lemmatized = [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('the', None), ('the', None)), 28198),\n",
       " ((('of', None), ('the', None)), 26053),\n",
       " ((('the', None), ('of', None)), 26053),\n",
       " ((('the', None), ('to', None)), 18468),\n",
       " ((('to', None), ('the', None)), 18468),\n",
       " ((('in', None), ('the', None)), 17600),\n",
       " ((('the', None), ('in', None)), 17600),\n",
       " ((('the', None), ('be', 'v')), 17523),\n",
       " ((('be', 'v'), ('the', None)), 17523),\n",
       " ((('say', 'v'), ('the', None)), 16812)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "from collections import Counter\n",
    "\n",
    "spansize = 5\n",
    "cooccs_surface = Counter()\n",
    "\n",
    "for i, w in enumerate(lemmas):\n",
    "    if len(w) > 1:\n",
    "        span_range = list(range(max(i- spansize, 0), i))\n",
    "        span_range.extend(range(i+1, min(i + spansize + 1, len(lemmas))))\n",
    "        for cw in [lemmas[idx] for idx in span_range]:\n",
    "            cooccs_surface[(w, cw)] += 1\n",
    "        \n",
    "cooccs_surface.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, checking word co-occurances in a `±5 word span` within the text returns some less-than-interesting results. \n",
    "\n",
    "Let's do the same again but filter for **only nouns**, as this should return some more interesting connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('mln', 'n'), ('mln', 'n')), 10416),\n",
       " ((('mln', 'n'), ('v', 'n')), 9346),\n",
       " ((('v', 'n'), ('mln', 'n')), 9346),\n",
       " ((('ct', 'n'), ('vs', 'a')), 6787),\n",
       " ((('ct', 'n'), ('ct', 'n')), 6500),\n",
       " ((('ct', 'n'), ('net', 'a')), 5972),\n",
       " ((('company', 'n'), ('the', None)), 4875),\n",
       " ((('loss', 'n'), ('vs', 'a')), 4160),\n",
       " ((('loss', 'n'), ('loss', 'n')), 3832),\n",
       " ((('dlrs', 'n'), ('mln', 'n')), 3581)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_cooccs = Counter()\n",
    "\n",
    "for i, w in enumerate(lemmas):\n",
    "    if w[1] == \"n\":\n",
    "        span_range = list(range(max(i- spansize, 0), i))\n",
    "        span_range.extend(range(i+1, min(i + spansize + 1, len(lemmas))))\n",
    "        for cw in [lemmas[idx] for idx in span_range]:\n",
    "            noun_cooccs[(w, cw)] += 1\n",
    "        \n",
    "noun_cooccs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corpus contains a lot of dense numerical information, meaning high rates of co-occurances for unusual strings like `\"dlrs\", \"mln\", \"ct\", and \"vs\"`.\n",
    "\n",
    "**We'll have to filter this quite a bit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('say', 'v'), 24189),\n",
       " (('year', 'n'), 6612),\n",
       " (('share', 'n'), 5489),\n",
       " (('loss', 'n'), 5486),\n",
       " (('company', 'n'), 4771),\n",
       " (('bank', 'n'), 4295),\n",
       " (('price', 'n'), 3806),\n",
       " (('u.s', 'n'), 3588),\n",
       " (('profit', 'n'), 3374),\n",
       " (('market', 'n'), 3371)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "filtered = []\n",
    "nouns = []\n",
    "freqs = nltk.FreqDist(lemmas)\n",
    "stops = set(stopwords.words('english'))\n",
    "odd = \"mln ct v dlrs pct net vs shr\".split()\n",
    "\n",
    "for word in lemmas:\n",
    "    if (freqs[word] >= 10 and \n",
    "        word[0] not in stops and\n",
    "        word[0] not in odd and\n",
    "        word[1] != None):\n",
    "        filtered.append(word)\n",
    "        if word[1] == \"n\":\n",
    "            nouns.append(word)\n",
    "            \n",
    "filt_fd = nltk.FreqDist(filtered)\n",
    "noun_fd = nltk.FreqDist(nouns)\n",
    "\n",
    "filt_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a much nicer frequency distribution of words!\n",
    "\n",
    "I chose to remove all **stopwords** as well as a list of unusual financial-related words that appeared commonly.\n",
    "\n",
    "I also only kept words that have been PoS tagged - meaning just *nouns, verbs, adjectives, and adverbs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('loss', 'n'), ('loss', 'n')), 3832),\n",
       " ((('profit', 'n'), ('loss', 'n')), 2164),\n",
       " ((('loss', 'n'), ('profit', 'n')), 2164),\n",
       " ((('company', 'n'), ('say', 'v')), 2109),\n",
       " ((('bank', 'n'), ('say', 'v')), 1226),\n",
       " ((('loss', 'n'), ('rev', 'n')), 1111),\n",
       " ((('rev', 'n'), ('loss', 'n')), 1111),\n",
       " ((('year', 'n'), ('last', 'a')), 1036),\n",
       " ((('corp', 'n'), ('say', 'v')), 976),\n",
       " ((('profit', 'n'), ('profit', 'n')), 946)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_cooccs_surface = Counter()\n",
    "\n",
    "for word, freq in cooccs_surface.items():\n",
    "    if word[0] in noun_fd and word[1] in filt_fd:\n",
    "        filtered_cooccs_surface[word] = freq\n",
    "\n",
    "filtered_cooccs_surface.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector representations (60 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (20 points)\n",
    "\n",
    "Weight the counts in the space you created for the previous question by using the following association measures on both spaces:\n",
    "\n",
    "1. One **measure of your choice** among those available in the [nltk.BigramAssocMeasures](http://www.nltk.org/howto/metrics.html#association-measures) module.\n",
    "2. The **Positive Local Mutual Information** measure (as shown in class/lab).\n",
    "\n",
    "**Possible extra**\n",
    "\n",
    "3. Also use the **smoothed ppmi measure** proposed by [Levy et al. (2015)](http://www.aclweb.org/anthology/Q15-1016). Recall that the authors proposed to smooth the ppmi by raising the context counts to the power of $\\alpha$ (where $\\alpha= 0.75$ is reported to work well). That is, if $V_c$ is the vocabulary of all the contexts in a given space and $f(c)$ is the context frequency, they proposed the following association measure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$PPMI_\\alpha (w,c) = max \\left(0, \\ log_2 \\left(\\frac{p(w,c)}{p(w) \\cdot p_\\alpha(c)}\\right)  \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$where: \\ \\ p_\\alpha(c) = \\frac{f(c)^\\alpha}{\\sum_{c' \\in V_c} f(c')^\\alpha}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('corpus', 'n'), ('christi', 'n')), 653329.0),\n",
       " ((('wk', 'v'), ('named-a', 'a')), 653329.0),\n",
       " ((('ttl-f', 'a'), ('usdaprj-g', 'a')), 593934.5454406304),\n",
       " ((('karl', 'n'), ('otto', 'n')), 581664.7434793665),\n",
       " ((('lufkin', 'n'), ('jenrette', 'n')), 559994.5713970838),\n",
       " ((('bra', 'n'), ('kanon', 'n')), 559992.8570169042),\n",
       " ((('poison', 'n'), ('pill', 'n')), 525771.6285160262),\n",
       " ((('costa', 'n'), ('rica', 'n')), 487291.86140952766),\n",
       " ((('brace', 'n'), ('jovanovich', 'n')), 435545.9997959108),\n",
       " ((('burnham', 'n'), ('lambert', 'n')), 431711.11590458115)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "from nltk.collocations import (BigramAssocMeasures as bam, \n",
    "                               BigramCollocationFinder as bcf)\n",
    "\n",
    "# search for strict bigrams (span 2)\n",
    "finder = bcf.from_words(filtered, window_size=2)\n",
    "finder.apply_freq_filter(10)\n",
    "chi_scored = finder.score_ngrams(bam.chi_sq)\n",
    "\n",
    "chi_scored[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('loss', 'n'), ('loss', 'n')), 41293.756528189544),\n",
       " ((('profit', 'n'), ('loss', 'n')), 23052.940700843934),\n",
       " ((('loss', 'n'), ('profit', 'n')), 23052.940700843934),\n",
       " ((('company', 'n'), ('say', 'v')), 16820.18686030617),\n",
       " ((('loss', 'n'), ('rev', 'n')), 11428.373852315883),\n",
       " ((('rev', 'n'), ('loss', 'n')), 11428.373852315883),\n",
       " ((('year', 'n'), ('last', 'a')), 9725.836218613771),\n",
       " ((('profit', 'n'), ('profit', 'n')), 9611.772760273878),\n",
       " ((('bank', 'n'), ('say', 'v')), 9004.31507699253),\n",
       " ((('state', 'n'), ('united', 'a')), 7825.757078502919)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "def ppmi(o_11, r_1, c_1, n):\n",
    "    \"Positive Pointwise Mutual Information (Church & Hanks, 1990)\"\n",
    "    observed = o_11\n",
    "    expected = (r_1*c_1)/n \n",
    "    res = log(observed/expected,2)\n",
    "    return max(0, res)\n",
    "\n",
    "def plmi(o_11, r_1, c_1, n):\n",
    "    \"Positive Local Mutual Information, useful for leveraging the low-frequency bias of the PPMI\"\n",
    "    res = o_11 * ppmi(o_11, r_1, c_1, n)\n",
    "    return res\n",
    "\n",
    "plmis_surface = Counter()\n",
    "\n",
    "N = sum(cooccs_surface.values())\n",
    "\n",
    "for words, freq in filtered_cooccs_surface.items():\n",
    "    plmis_surface[words] = plmi(freq, freqs[words[0]], freqs[words[1]], N)\n",
    "    \n",
    "plmis_surface.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('het', 'n'), ('comite', 'n')), 39.14774236628333),\n",
       " ((('comite', 'n'), ('het', 'n')), 39.14774236628333),\n",
       " ((('corpus', 'n'), ('christi', 'n')), 38.72636269329684),\n",
       " ((('christi', 'n'), ('corpus', 'n')), 38.72636269329684),\n",
       " ((('pill', 'n'), ('poison', 'n')), 38.6710650014388),\n",
       " ((('poison', 'n'), ('pill', 'n')), 38.64617870882526),\n",
       " ((('lufkin', 'n'), ('jenrette', 'n')), 38.64617870882526),\n",
       " ((('jenrette', 'n'), ('lufkin', 'n')), 38.59057571801638),\n",
       " ((('siegler', 'n'), ('lear', 'a')), 38.49207628096376),\n",
       " ((('hajime', 'n'), ('tamura', 'n')), 38.436104773522466)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sppmi(o_11, r_1, c_1, n):\n",
    "    \"Smoothed PPMI with context counts raised to the power a = 0.75\"\n",
    "    p = c_1/n\n",
    "    a = 0.75\n",
    "    pac = (p ** a) / (p ** a + (1 - p) ** a)\n",
    "    exp = (r_1/n) * pac\n",
    "    res = log(o_11 / exp, 2)\n",
    "    return max(0, res)\n",
    "\n",
    "sppmis_surface = Counter()\n",
    "\n",
    "for words, freq in filtered_cooccs_surface.items():\n",
    "    sppmis_surface[words] = sppmi(freq, freqs[words[0]], freqs[words[1]], N)\n",
    "    \n",
    "sppmis_surface.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points)\n",
    "\n",
    "Up to this point, you should have created 2 different distributional spaces (3 if you did the extra).\n",
    "\n",
    "Use **Singular Value Decomposition** to reduce their dimensionality retaining only the first 100 dimensions. For this question, you can either re-use the SVD code from the lab, or import the SVD functions from external libraries such as [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) or [scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html).\n",
    "\n",
    "**Possible extra**\n",
    "\n",
    "Find the 'optimal' number of dimensions to retain using the approach shown in the lab. Use a model with this dimensionality instead of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# lemma to row/column index mappings\n",
    "sorted_vectors = sorted(noun_fd)\n",
    "vectors_indices = dict((v,i) for i,v in enumerate(sorted_vectors))\n",
    "contexts_indices = dict((v,i) for i,v in enumerate(sorted(filt_fd)))\n",
    "\n",
    "\n",
    "# create matrix to store PLMI values\n",
    "plmiMat = np.zeros((len(vectors_indices), len(contexts_indices)))\n",
    "for pair, weight in plmis_surface.items():\n",
    "    plmiMat[vectors_indices[pair[0]]][contexts_indices[pair[1]]] = weight\n",
    "    \n",
    "\n",
    "# create matrix to store Smoothed PPMI values\n",
    "sppmiMat = np.zeros((len(vectors_indices), len(contexts_indices)))\n",
    "for pair, weight in sppmis_surface.items():\n",
    "    sppmiMat[vectors_indices[pair[0]]][contexts_indices[pair[1]]] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import linalg, dot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "U, s, Vt = linalg.svd(plmiMat)\n",
    "\n",
    "if not U[U>0].size > (U.size / 2):\n",
    "    U = -U\n",
    "    Vt = -Vt\n",
    "    \n",
    "rel_variance = ( s**2 / sum(s**2) ) * 100\n",
    "\n",
    "y_values =  rel_variance[:100] \n",
    "x_values = np.arange(len(y_values))\n",
    "\n",
    "plt.plot(x_values, y_values, linestyle = '-')\n",
    "\n",
    "plt.xlabel(\"Singular Values\", labelpad = 20)\n",
    "plt.ylabel(\"Relative Variance (%)\", labelpad = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the above plot, the relative variance percentage really drops off between 10 and 20 dimensions.\n",
    "\n",
    "I'll stick with **20** dimensions for SVD from here on, as to make sure little information is lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word vectors most similar to 'year' according to the plmi space:\n",
      "\n",
      "('month', 'n') 0.9248842642775666\n",
      "('cathay', 'n') 0.9003143348664894\n",
      "('september', 'n') 0.8878204686710206\n",
      "('autumn', 'n') 0.8875817946102142\n",
      "(\"year's\", 'n') 0.8863390215581793\n"
     ]
    }
   ],
   "source": [
    "dim = 20\n",
    "\n",
    "k = 5\n",
    "target_idx = vectors_indices[(\"year\", \"n\")] \n",
    "\n",
    "plmi_svd = TruncatedSVD(n_components=dim).fit_transform(plmiMat)\n",
    "plmi_cos_sim = cosine_similarity(plmi_svd)\n",
    "\n",
    "print(\"word vectors most similar to 'year' according to the plmi space:\\n\")\n",
    "\n",
    "for idx in plmi_cos_sim[target_idx,].argsort()[::-1][1:k+1]:\n",
    "    print(sorted_vectors[idx], plmi_cos_sim[target_idx, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word vectors most similar to 'year' according to the sppmi space:\n",
      "\n",
      "('sale', 'n') 0.9389758166785845\n",
      "('company', 'n') 0.9267187841007433\n",
      "('month', 'n') 0.9256464828241585\n",
      "('u.s', 'n') 0.9187203066849902\n",
      "('said', 'n') 0.9144199364175969\n"
     ]
    }
   ],
   "source": [
    "sppmi_svd = TruncatedSVD(n_components=dim).fit_transform(sppmiMat)\n",
    "sppmi_cos_sim = cosine_similarity(sppmi_svd)\n",
    "\n",
    "print(\"word vectors most similar to 'year' according to the sppmi space:\\n\")\n",
    "\n",
    "for idx in sppmi_cos_sim[target_idx,].argsort()[::-1][1:k+1]:\n",
    "    print(sorted_vectors[idx], sppmi_cos_sim[target_idx, idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Train a Word2Vec model the same corpus, for example using [gensim](https://radimrehurek.com/gensim). Make sure to motivate the choice of your hyperparameters.\n",
    "\n",
    "**Possible extra**\n",
    "\n",
    "*Fine-tuning* is the process of starting from a pre-trained embedding model and training it some more using new data. Try to use a pre-trained model from gensim and to fine-tune it on the Reuters corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "wv = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=11401, vector_size=100, alpha=0.12)\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vector_size': 100, # same size as other spaces\n",
    "    'alpha': 0.12, # initial learning rate for SGD - seems to produce best results\n",
    "    'window': 5, # same collocation span as before\n",
    "    'min_count': 5, # only take words with frequency > 5\n",
    "    'workers': 4, # cpu cores\n",
    "    'sg': 1, # implements skip-gram\n",
    "    'epochs': 5 # iterations - 5 seemed reasonable\n",
    "}\n",
    "\n",
    "untagged_sents = []\n",
    "for sent in lem_sents:\n",
    "    untagged_sents.append([word for word, tag in sent])\n",
    "\n",
    "# creating Word2Vec space for the list of untagged lemmatized sentences\n",
    "lemma_w2v = Word2Vec(untagged_sents, **parameters)\n",
    "print(lemma_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=55520, vector_size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# fine-tuning pretrained model onto the reuters corpus\n",
    "tuned_w2v = Word2Vec(vector_size=100, min_count=1)\n",
    "tuned_w2v.build_vocab(untagged_sents)\n",
    "\n",
    "tuned_w2v.build_vocab(list(wv.index_to_key), update=True)\n",
    "tuned_w2v.train(untagged_sents, total_examples=tuned_w2v.corpus_count, epochs=tuned_w2v.epochs)\n",
    "print(tuned_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 0.6938016414642334),\n",
       " ('have', 0.6766988635063171),\n",
       " ('also', 0.665836751461029),\n",
       " ('the', 0.6245516538619995),\n",
       " ('be', 0.6065378785133362),\n",
       " ('add', 0.5915255546569824),\n",
       " ('that', 0.5855926871299744),\n",
       " ('tell', 0.5822742581367493),\n",
       " ('it', 0.5718165040016174),\n",
       " ('however', 0.5317421555519104)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_w2v.wv.most_similar([\"say\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on semantic similarity (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Evaluate the performance of your models on a **semantic similarity task**. Using `SimLex-999` as gold standard. Evaluate all of your models on the dataset in `data/SimLex-999.txt`, and determine the best performing model. Note: There should be 5 to 8 model evaluations in total. 5 if you did not do any extra (2 from 4.1 + 2 from 4.2 + 1 from 4.3), and 8 if you did them all (3 from 4.1 + 3 from 4.2 + 2 from 4.3).\n",
    "\n",
    "1. Your evaluation should follow the approach shown in lab 4 (Section 1.6: \"Evaluating your Model\"), using a **correlation measure** on model predictions and the (human) gold standard. \n",
    "2. Remember to **visualize** your results (e.g., as bar plots).\n",
    "3. Take note (and report) the overlap between your models and the SimLex-999 dataset, i.e., how many pairs are shared by your model and the evaluation dataset.\n",
    "4. Make sure to discuss your results and provide your reasoning on them.\n",
    "\n",
    "### Remarks\n",
    "\n",
    "- The 'SimLex-999' dataset is described in `data/SimLex-999.README.txt`, and [the author's github page](https://fh295.github.io/simlex.html). Hint: the relevant judgements are those in the `SimLex999` column.\n",
    "- To directly compare the models against the gold standard, you will have to find the *overlap* between them, i.e. the pairs that occur in your model *and* the evaluation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word1', 'word2', 'POS', 'SimLex999', 'conc(w1)', 'conc(w2)', 'concQ', 'Assoc(USF)', 'SimAssoc333', 'SD(SimLex)']\n",
      "['old', 'new', 'A', '1.58', '2.72', '2.81', '2', '7.25', '1', '0.41']\n",
      "['smart', 'intelligent', 'A', '9.2', '1.75', '2.46', '1', '7.11', '1', '0.67']\n",
      "['hard', 'difficult', 'A', '8.77', '3.76', '2.21', '2', '5.94', '1', '1.19']\n",
      "['happy', 'cheerful', 'A', '9.55', '2.56', '2.34', '1', '5.85', '1', '2.18']\n",
      "['hard', 'easy', 'A', '0.95', '3.76', '2.07', '2', '5.82', '1', '0.93']\n",
      "['fast', 'rapid', 'A', '8.75', '3.32', '3.07', '2', '5.66', '1', '1.68']\n",
      "['happy', 'glad', 'A', '9.17', '2.56', '2.36', '1', '5.49', '1', '1.59']\n",
      "['short', 'long', 'A', '1.23', '3.61', '3.18', '2', '5.36', '1', '1.58']\n",
      "['stupid', 'dumb', 'A', '9.58', '1.75', '2.36', '1', '5.26', '1', '1.48']\n",
      "['weird', 'strange', 'A', '8.93', '1.59', '1.86', '1', '4.26', '1', '1.3']\n",
      "['wide', 'narrow', 'A', '1.03', '3.06', '3.04', '2', '4.06', '1', '0.58']\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/SimLex-999.txt\") as f:\n",
    "    for n, line in enumerate(f.read().split(\"\\n\")):\n",
    "        items = line.split(\"\\t\")\n",
    "        print(items)\n",
    "        if n>10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>8.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>9.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>join</td>\n",
       "      <td>acquire</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>send</td>\n",
       "      <td>attend</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>gather</td>\n",
       "      <td>attend</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>absorb</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>attend</td>\n",
       "      <td>arrive</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1        word2 SimLex999\n",
       "1       old          new      1.58\n",
       "2     smart  intelligent       9.2\n",
       "3      hard    difficult      8.77\n",
       "4     happy     cheerful      9.55\n",
       "5      hard         easy      0.95\n",
       "..      ...          ...       ...\n",
       "995    join      acquire      2.85\n",
       "996    send       attend      1.67\n",
       "997  gather       attend       4.8\n",
       "998  absorb     withdraw      2.97\n",
       "999  attend       arrive      6.08\n",
       "\n",
       "[999 rows x 3 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sim_array = []\n",
    "\n",
    "with open(\"data/SimLex-999.txt\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        sim_array.append(line.split(\"\\t\"))\n",
    "    \n",
    "# organising data to make it easy to compare to later\n",
    "df = pd.DataFrame(sim_array, columns=(sim_array[0])).drop(index=[0,1000])\n",
    "\n",
    "# dropping redundant columns from the data\n",
    "df = df.drop(columns=['POS', 'conc(w1)', 'conc(w2)', 'concQ','Assoc(USF)', 'SimAssoc333', 'SD(SimLex)'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dollar', 'people', 8.24),\n",
       " ('tin', 'metal', 8.52),\n",
       " ('business', 'company', 9.06),\n",
       " ('tax', 'income', 8.44),\n",
       " ('pact', 'agreement', 9.39),\n",
       " ('money', 'capital', 5.26),\n",
       " ('home', 'state', 2.1),\n",
       " ('fee', 'payment', 5.09),\n",
       " ('business', 'industry', 9.57),\n",
       " ('cereal', 'wheat', 8.88)]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the next two functions are horribly inefficient but they work and I didn't have time to re-write\n",
    "\n",
    "plmi_overlaps = []\n",
    "\n",
    "for pair, score in plmis_surface.items():\n",
    "    new_pair = (pair[0][0], pair[1][0])\n",
    "    if new_pair in list(zip(df[\"word1\"], df[\"word2\"])):\n",
    "        try:\n",
    "            sim = plmi_cos_sim[vectors_indices[pair[0]], vectors_indices[pair[1]]]\n",
    "            plmi_overlaps.append((pair[0][0], pair[1][0], round(10 * sim, 2)))\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "plmi_overlaps[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dollar', 'people', 8.16),\n",
       " ('tin', 'metal', 8.38),\n",
       " ('business', 'company', 8.92),\n",
       " ('tax', 'income', 9.09),\n",
       " ('pact', 'agreement', 9.16),\n",
       " ('money', 'capital', 8.73),\n",
       " ('home', 'state', 8.11),\n",
       " ('fee', 'payment', 8.69),\n",
       " ('business', 'industry', 9.46),\n",
       " ('cereal', 'wheat', 8.61)]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sppmi_overlaps = []\n",
    "\n",
    "for pair, score in sppmis_surface.items():\n",
    "    new_pair = (pair[0][0], pair[1][0])\n",
    "    if new_pair in list(zip(df[\"word1\"], df[\"word2\"])):\n",
    "        try:\n",
    "            sim = sppmi_cos_sim[vectors_indices[pair[0]], vectors_indices[pair[1]]]\n",
    "            sppmi_overlaps.append((pair[0][0], pair[1][0], round(10 * sim, 2)))\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "sppmi_overlaps[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nice', 'generous', 2.58),\n",
       " ('confident', 'sure', 4.99),\n",
       " ('large', 'big', 6.86),\n",
       " ('big', 'broad', 0.9),\n",
       " ('unnecessary', 'necessary', 3.53)]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# much more efficient\n",
    "\n",
    "w2v_overlaps = []\n",
    "for w1, w2 in list(zip(df[\"word1\"], df[\"word2\"])):\n",
    "    if w1 in lemma_w2v.wv and w2 in lemma_w2v.wv:\n",
    "        w2v_overlaps.append((w1, w2, round(10 * lemma_w2v.wv.similarity(w1, w2), 2)))\n",
    "        \n",
    "w2v_overlaps[20:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('impatient', 'anxious', 5.85),\n",
       " ('big', 'broad', 3.55),\n",
       " ('strong', 'proud', 3.07),\n",
       " ('unnecessary', 'necessary', 7.01),\n",
       " ('bad', 'great', 6.73)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_w2v_overlaps = []\n",
    "for w1, w2 in list(zip(df[\"word1\"], df[\"word2\"])):\n",
    "    if w1 in tuned_w2v.wv and w2 in tuned_w2v.wv:\n",
    "        tuned_w2v_overlaps.append((w1, w2, round(10 * tuned_w2v.wv.similarity(w1, w2), 2)))\n",
    "        \n",
    "tuned_w2v_overlaps[30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>PLMI Space</th>\n",
       "      <th>Smoothed PPMI</th>\n",
       "      <th>Lemma W2V</th>\n",
       "      <th>Fine-Tuned W2V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>south</td>\n",
       "      <td>north</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.09</td>\n",
       "      <td>9.42</td>\n",
       "      <td>4.84</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>area</td>\n",
       "      <td>region</td>\n",
       "      <td>9.47</td>\n",
       "      <td>9.36</td>\n",
       "      <td>8.97</td>\n",
       "      <td>5.46</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>navy</td>\n",
       "      <td>army</td>\n",
       "      <td>6.43</td>\n",
       "      <td>8.80</td>\n",
       "      <td>9.11</td>\n",
       "      <td>5.95</td>\n",
       "      <td>8.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tax</td>\n",
       "      <td>income</td>\n",
       "      <td>2.38</td>\n",
       "      <td>8.44</td>\n",
       "      <td>9.09</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>floor</td>\n",
       "      <td>ceiling</td>\n",
       "      <td>1.73</td>\n",
       "      <td>8.26</td>\n",
       "      <td>8.64</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>business</td>\n",
       "      <td>industry</td>\n",
       "      <td>7.02</td>\n",
       "      <td>9.57</td>\n",
       "      <td>9.46</td>\n",
       "      <td>3.31</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>winter</td>\n",
       "      <td>season</td>\n",
       "      <td>6.27</td>\n",
       "      <td>8.86</td>\n",
       "      <td>9.45</td>\n",
       "      <td>4.98</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>window</td>\n",
       "      <td>door</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.34</td>\n",
       "      <td>6.29</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>metal</td>\n",
       "      <td>aluminum</td>\n",
       "      <td>7.25</td>\n",
       "      <td>8.73</td>\n",
       "      <td>9.40</td>\n",
       "      <td>4.25</td>\n",
       "      <td>7.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>attorney</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>9.35</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>5.53</td>\n",
       "      <td>8.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>business</td>\n",
       "      <td>company</td>\n",
       "      <td>9.02</td>\n",
       "      <td>9.06</td>\n",
       "      <td>8.92</td>\n",
       "      <td>2.70</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>money</td>\n",
       "      <td>capital</td>\n",
       "      <td>6.67</td>\n",
       "      <td>5.26</td>\n",
       "      <td>8.73</td>\n",
       "      <td>2.55</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>cereal</td>\n",
       "      <td>wheat</td>\n",
       "      <td>3.75</td>\n",
       "      <td>8.88</td>\n",
       "      <td>8.61</td>\n",
       "      <td>4.79</td>\n",
       "      <td>7.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>house</td>\n",
       "      <td>key</td>\n",
       "      <td>1.9</td>\n",
       "      <td>8.33</td>\n",
       "      <td>7.90</td>\n",
       "      <td>3.49</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>disc</td>\n",
       "      <td>computer</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.77</td>\n",
       "      <td>7.64</td>\n",
       "      <td>4.94</td>\n",
       "      <td>6.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>worker</td>\n",
       "      <td>employer</td>\n",
       "      <td>5.37</td>\n",
       "      <td>8.34</td>\n",
       "      <td>8.80</td>\n",
       "      <td>5.52</td>\n",
       "      <td>7.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>weekend</td>\n",
       "      <td>week</td>\n",
       "      <td>4</td>\n",
       "      <td>7.65</td>\n",
       "      <td>8.44</td>\n",
       "      <td>4.12</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>bean</td>\n",
       "      <td>coffee</td>\n",
       "      <td>5.15</td>\n",
       "      <td>8.97</td>\n",
       "      <td>8.09</td>\n",
       "      <td>4.51</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>pact</td>\n",
       "      <td>agreement</td>\n",
       "      <td>9.02</td>\n",
       "      <td>9.39</td>\n",
       "      <td>9.16</td>\n",
       "      <td>7.01</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>august</td>\n",
       "      <td>month</td>\n",
       "      <td>5.53</td>\n",
       "      <td>8.95</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.16</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>cattle</td>\n",
       "      <td>beef</td>\n",
       "      <td>7.03</td>\n",
       "      <td>8.41</td>\n",
       "      <td>8.74</td>\n",
       "      <td>4.10</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>corporation</td>\n",
       "      <td>business</td>\n",
       "      <td>9.02</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.77</td>\n",
       "      <td>1.53</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>danger</td>\n",
       "      <td>threat</td>\n",
       "      <td>8.78</td>\n",
       "      <td>9.09</td>\n",
       "      <td>8.97</td>\n",
       "      <td>5.16</td>\n",
       "      <td>7.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>day</td>\n",
       "      <td>morning</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.67</td>\n",
       "      <td>8.93</td>\n",
       "      <td>2.05</td>\n",
       "      <td>5.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>attention</td>\n",
       "      <td>interest</td>\n",
       "      <td>7.22</td>\n",
       "      <td>2.85</td>\n",
       "      <td>7.49</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>medium</td>\n",
       "      <td>news</td>\n",
       "      <td>3.65</td>\n",
       "      <td>5.44</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>fee</td>\n",
       "      <td>payment</td>\n",
       "      <td>7.15</td>\n",
       "      <td>5.09</td>\n",
       "      <td>8.69</td>\n",
       "      <td>2.77</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>river</td>\n",
       "      <td>sea</td>\n",
       "      <td>5.72</td>\n",
       "      <td>7.03</td>\n",
       "      <td>9.09</td>\n",
       "      <td>2.70</td>\n",
       "      <td>7.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>job</td>\n",
       "      <td>management</td>\n",
       "      <td>3.97</td>\n",
       "      <td>6.73</td>\n",
       "      <td>7.81</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>action</td>\n",
       "      <td>course</td>\n",
       "      <td>5.45</td>\n",
       "      <td>9.05</td>\n",
       "      <td>8.07</td>\n",
       "      <td>3.58</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>home</td>\n",
       "      <td>state</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.10</td>\n",
       "      <td>8.11</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>newspaper</td>\n",
       "      <td>information</td>\n",
       "      <td>5.65</td>\n",
       "      <td>9.70</td>\n",
       "      <td>8.51</td>\n",
       "      <td>2.65</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>communication</td>\n",
       "      <td>television</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.37</td>\n",
       "      <td>9.58</td>\n",
       "      <td>5.31</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>tin</td>\n",
       "      <td>metal</td>\n",
       "      <td>5.63</td>\n",
       "      <td>8.52</td>\n",
       "      <td>8.38</td>\n",
       "      <td>3.36</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>snow</td>\n",
       "      <td>storm</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.92</td>\n",
       "      <td>9.27</td>\n",
       "      <td>6.32</td>\n",
       "      <td>7.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>pact</td>\n",
       "      <td>condition</td>\n",
       "      <td>2.45</td>\n",
       "      <td>7.49</td>\n",
       "      <td>8.06</td>\n",
       "      <td>2.17</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>dollar</td>\n",
       "      <td>people</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.24</td>\n",
       "      <td>8.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word1        word2 SimLex999  PLMI Space  Smoothed PPMI  \\\n",
       "115          south        north       2.2        7.09           9.42   \n",
       "134           area       region      9.47        9.36           8.97   \n",
       "135           navy         army      6.43        8.80           9.11   \n",
       "171            tax       income      2.38        8.44           9.09   \n",
       "174          floor      ceiling      1.73        8.26           8.64   \n",
       "195       business     industry      7.02        9.57           9.46   \n",
       "196         winter       season      6.27        8.86           9.45   \n",
       "200         window         door      3.33        3.34           6.29   \n",
       "228          metal     aluminum      7.25        8.73           9.40   \n",
       "234       attorney       lawyer      9.35        9.90           9.14   \n",
       "236       business      company      9.02        9.06           8.92   \n",
       "239          money      capital      6.67        5.26           8.73   \n",
       "259         cereal        wheat      3.75        8.88           8.61   \n",
       "260          house          key       1.9        8.33           7.90   \n",
       "311           disc     computer       3.2        7.77           7.64   \n",
       "325         worker     employer      5.37        8.34           8.80   \n",
       "334        weekend         week         4        7.65           8.44   \n",
       "340           bean       coffee      5.15        8.97           8.09   \n",
       "352           pact    agreement      9.02        9.39           9.16   \n",
       "367         august        month      5.53        8.95           8.13   \n",
       "381         cattle         beef      7.03        8.41           8.74   \n",
       "385    corporation     business      9.02        7.75           7.77   \n",
       "430         danger       threat      8.78        9.09           8.97   \n",
       "445            day      morning      4.87        4.67           8.93   \n",
       "477      attention     interest      7.22        2.85           7.49   \n",
       "482         medium         news      3.65        5.44           7.40   \n",
       "485            fee      payment      7.15        5.09           8.69   \n",
       "540          river          sea      5.72        7.03           9.09   \n",
       "559            job   management      3.97        6.73           7.81   \n",
       "596         action       course      5.45        9.05           8.07   \n",
       "601           home        state      2.58        2.10           8.11   \n",
       "604      newspaper  information      5.65        9.70           8.51   \n",
       "605  communication   television       5.6        8.37           9.58   \n",
       "672            tin        metal      5.63        8.52           8.38   \n",
       "684           snow        storm       4.8        8.92           9.27   \n",
       "711           pact    condition      2.45        7.49           8.06   \n",
       "771         dollar       people       0.4        8.24           8.16   \n",
       "\n",
       "     Lemma W2V  Fine-Tuned W2V  \n",
       "115       4.84            6.61  \n",
       "134       5.46            7.85  \n",
       "135       5.95            8.17  \n",
       "171       4.90            5.06  \n",
       "174       2.72            4.31  \n",
       "195       3.31            4.86  \n",
       "196       4.98            7.83  \n",
       "200       2.78            2.46  \n",
       "228       4.25            7.54  \n",
       "234       5.53            8.89  \n",
       "236       2.70            6.10  \n",
       "239       2.55            4.53  \n",
       "259       4.79            7.27  \n",
       "260       3.49            5.81  \n",
       "311       4.94            6.68  \n",
       "325       5.52            7.42  \n",
       "334       4.12            5.99  \n",
       "340       4.51            7.31  \n",
       "352       7.01            7.83  \n",
       "367       3.16            5.42  \n",
       "381       4.10            7.93  \n",
       "385       1.53            3.71  \n",
       "430       5.16            7.98  \n",
       "445       2.05            5.39  \n",
       "477       1.76            3.54  \n",
       "482       0.87           -0.93  \n",
       "485       2.77            4.84  \n",
       "540       2.70            7.74  \n",
       "559       3.42            2.35  \n",
       "596       3.58            7.50  \n",
       "601       1.32            1.79  \n",
       "604       2.65            4.47  \n",
       "605       5.31            8.11  \n",
       "672       3.36            5.09  \n",
       "684       6.32            7.58  \n",
       "711       2.17            4.94  \n",
       "771       2.30            3.85  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframes for each space and merging into one\n",
    "\n",
    "plmi_df = pd.DataFrame(plmi_overlaps, columns=[\"word1\", \"word2\", \"PLMI Space\"])\n",
    "sppmi_df = pd.DataFrame(sppmi_overlaps, columns=[\"word1\", \"word2\", \"Smoothed PPMI\"])\n",
    "w2v_df = pd.DataFrame(w2v_overlaps, columns=[\"word1\", \"word2\", \"Lemma W2V\"])\n",
    "tuned_df = pd.DataFrame(tuned_w2v_overlaps, columns=[\"word1\", \"word2\", \"Fine-Tuned W2V\"])\n",
    "\n",
    "merged = pd.merge(df, plmi_df, how=\"left\", on=[\"word1\", \"word2\"])\n",
    "merged = pd.merge(merged, sppmi_df, how=\"left\", on=[\"word1\", \"word2\"])\n",
    "merged = pd.merge(merged, w2v_df, how=\"left\", on=[\"word1\", \"word2\"])\n",
    "merged = pd.merge(merged, tuned_df, how=\"left\", on=[\"word1\", \"word2\"])\n",
    "\n",
    "disp = merged.dropna(subset=['PLMI Space', 'Smoothed PPMI',], thresh=2)\n",
    "disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, many of the results provided by the PLMI measure are quite different to the human gold standard. This could be due to the relatively low size of the reuters corpus, as well as the lack of range in its vocabulary. \n",
    "\n",
    "The **Smoothed PPMI** space seems to give results closer to that of **SimLex999**, but tends to rate antonyms more closely than SimLex does, perhaps because they appear in similar contexts.\n",
    "\n",
    "There are only 37 pairs of words that appear in both spaces, which is a tiny portion of the SimLex dataset.\n",
    "\n",
    "However, both of the word2vec spaces overlap with more than **70%** of the SimLex data, providing many more useful insights.\n",
    "\n",
    "Above I display only the **37** words which appear in all the spaces, but the rest are accessible in `merged`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13388256246422825, 0.13365393315276552, 0.15418280774238294, 0.15135564131845616]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "rhos = []\n",
    "for space in merged.columns[3:]:\n",
    "    \n",
    "    rho, pval = spearmanr(merged[\"SimLex999\"], merged[space])\n",
    "    rhos.append(rho)\n",
    "    \n",
    "print(rhos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spearman test results in very similar rho values for both the PLMI and Smoothed PPMI spaces, even though they give very different cosine similarities for most of the overlapping words.\n",
    "\n",
    "Both of the Word2Vec models are good, with the fine-tuned one surprisingly performing slightly worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 960x640 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(0, len(rhos)), rhos, width=0.8, color=\"lightblue\")\n",
    "plt.xticks(range(0, len(rhos)), merged.columns[3:])\n",
    "plt.figure(dpi=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
